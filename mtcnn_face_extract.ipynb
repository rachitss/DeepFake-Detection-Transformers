{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet18\n",
    "from albumentations import Normalize, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing as mp\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Running on device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79c864",
   "metadata": {},
   "source": [
    "# Face Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'D:\\\\W\\\\VS\\\\VS Folder\\\\DFD\\\\DFDC\\\\deepfake-detection-challenge\\\\train_sample_videos\\\\'\n",
    "METADATA_PATH = TRAIN_DIR + 'metadata.json'\n",
    "TMP_DIR = 'D:\\\\W\\\\VS\\\\VS Folder\\\\DFD\\\\DFDC MTCNN Extracted'\n",
    "\n",
    "SCALE = 0.25\n",
    "N_FRAMES = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd37dc",
   "metadata": {},
   "source": [
    "## Face Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceExtractor:\n",
    "    def __init__(self, detector, n_frames=None, resize=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            n_frames {int} -- Total number of frames to load. These will be evenly spaced\n",
    "                throughout the video. If not specified (i.e., None), all frames will be loaded.\n",
    "                (default: {None})\n",
    "            resize {float} -- Fraction by which to resize frames from original prior to face\n",
    "                detection. A value less than 1 results in downsampling and a value greater than\n",
    "                1 result in upsampling. (default: {None})\n",
    "        \"\"\"\n",
    "\n",
    "        self.detector = detector\n",
    "        self.n_frames = n_frames\n",
    "        self.resize = resize\n",
    "    \n",
    "    def __call__(self, filename, save_dir):\n",
    "        \"\"\"Load frames from an MP4 video, detect faces and save the results.\n",
    "\n",
    "        Parameters:\n",
    "            filename {str} -- Path to video.\n",
    "            save_dir {str} -- The directory where results are saved.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create video reader and find length\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Pick 'n_frames' evenly spaced frames to sample\n",
    "        if self.n_frames is None:\n",
    "            sample = np.arange(0, v_len)\n",
    "        else:\n",
    "            sample = np.linspace(0, v_len - 1, self.n_frames).astype(int)\n",
    "\n",
    "        # Loop through frames\n",
    "        for j in range(v_len):\n",
    "            success = v_cap.grab()\n",
    "            if j in sample:\n",
    "                # Load frame\n",
    "                success, frame = v_cap.retrieve()\n",
    "                if not success:\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "                \n",
    "                # Resize frame to desired size\n",
    "                if self.resize is not None:\n",
    "                    frame = frame.resize([int(d * self.resize) for d in frame.size])\n",
    "\n",
    "                save_path = os.path.join(save_dir, f'{j}.png')\n",
    "\n",
    "                self.detector([frame], save_path=save_path)\n",
    "\n",
    "        v_cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dadd47",
   "metadata": {},
   "source": [
    "## Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METADATA_PATH, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(\n",
    "    [\n",
    "        (video_file, metadata[video_file]['label'], metadata[video_file]['split'], metadata[video_file]['original'] if 'original' in metadata[video_file].keys() else '')\n",
    "        for video_file in metadata.keys()\n",
    "    ],\n",
    "    columns=['filename', 'label', 'split', 'original']\n",
    ")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1750f6",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face detector\n",
    "face_detector = MTCNN(margin=14, keep_all=True, factor=0.5, device=device).eval()\n",
    "\n",
    "# Define face extractor\n",
    "face_extractor = FaceExtractor(detector=face_detector, n_frames=N_FRAMES, resize=SCALE)\n",
    "\n",
    "# Get the paths of all train videos\n",
    "all_train_videos = glob.glob(os.path.join(TRAIN_DIR, '*.mp4'))\n",
    "\n",
    "# Get the paths of all train videos\n",
    "all_train_videos = glob.glob(os.path.join(TRAIN_DIR, '*.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b967d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for path in tqdm(all_train_videos):\n",
    "        file_name = path.split('\\\\')[-1]\n",
    "\n",
    "        save_dir = os.path.join(TMP_DIR, file_name.split(\".\")[0])\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        # Detect all faces appear in the video and save them.\n",
    "        face_extractor(path, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9efca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea234b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
